<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Download and convert mobility datasets • spanishoddata</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
<link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../apple-touch-icon.png">
<link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../apple-touch-icon-120x120.png">
<link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../apple-touch-icon-76x76.png">
<link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../apple-touch-icon-60x60.png">
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.4.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.4.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><script src="convert_files/libs/quarto-html/popper.min.js"></script><script src="convert_files/libs/quarto-html/tippy.umd.min.js"></script><link href="convert_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="convert_files/libs/quarto-html/light-border.css" rel="stylesheet">
<!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Download and convert mobility datasets">
<meta property="og:image" content="https://rOpenSpain.github.io/spanishoddata/reference/figures/card.png">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:creator" content="@rOpenSpain">
<meta name="twitter:site" content="@rOpenSpain">
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Roboto+Mono&amp;family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&amp;display=swap" rel="stylesheet">
<!-- rogtemplate style sheet --><link href="../BS5/rostemplate.min.css" rel="stylesheet">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar fixed-top navbar-light navbar-expand-lg bg-light"><div class="container">
  <a class="navbar-brand me-2" href="../index.html">
    <img src="../apple-touch-icon-180x180.png" alt="spanishoddata logo" height="40" class="d-inline-block me-1">spanishoddata</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.0.1</small>

    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="active nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-articles" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Articles</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-articles">
<li><a class="dropdown-item" href="../articles/v1-2020-2021-mitma-data-codebook.html">Codebook and cookbook for v1 (2020-2021) Spanish mobility data</a></li>
    <li><a class="dropdown-item" href="../articles/v2-2022-onwards-mitma-data-codebook.html">Codebook and cookbook for v2 (2022 onwards) Spanish mobility data</a></li>
    <li><a class="dropdown-item" href="../articles/convert.html">Download and convert mobility datasets</a></li>
    <li><a class="dropdown-item" href="../articles/uses.html">Use cases</a></li>
    <li><a class="dropdown-item" href="../articles/flowmaps-static.html">Making static flow maps</a></li>
  </ul>
</li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json">
</form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/rOpenSpain/spanishoddata/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul>
</div>
  </div>
</nav><div class="container template-quarto">
<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="../logo.png" class="logo" alt=""><h1>Download and convert mobility datasets</h1>




      <small class="dont-index">Source: <a href="https://github.com/rOpenSpain/spanishoddata/blob/64-stop-piling-up-of-xml-files-with-file-links/vignettes/convert.qmd" class="external-link"><code>vignettes/convert.qmd</code></a></small>
      <div class="d-none name"><code></code></div>
    </div>






    <section class="section level2" data-number="1"><h2 data-number="1" id="intro">
<span class="header-section-number">1</span> Introduction<a class="anchor" aria-label="anchor" href="#intro"></a>
</h2>
<p><strong>TL;DR (too long, didn’t read): For analysing more than 1 week of data, use <code><a href="../reference/spod_convert.html">spod_convert()</a></code> to convert the data into <code>DuckDB</code> and <code><a href="../reference/spod_connect.html">spod_connect()</a></code> to connect to it for analysis using <a href="https://dplyr.tidyverse.org" class="external-link">dplyr</a>. Skip to the <a href="#duckdb">section about it</a>.</strong></p>
<p>The main focus of this vignette is to show how to get long periods of origin-destination data for analysis. First, we describe and compare the two ways to get the mobility data using origin-destination data as an example. The package functions and overall approaches are the same for working with other types of data available through the package, such as the number of trips, overnight stays and any other data. Then we show how to get a few days of origin-destination data with <code><a href="../reference/spod_get.html">spod_get()</a></code>. Finally, we show how to download and convert multiple weeks, months or even years of origin-destination data into analysis-ready formats. See description of datasets in the <a href="v1-2020-2021-mitma-data-codebook.html">Codebook and cookbook for v1 (2020-2021) Spanish mobility data</a> and in the <a href="v2-2022-onwards-mitma-data-codebook.html">Codebook and cookbook for v2 (2022 onwards) Spanish mobility data</a>.</p>
</section><section class="section level2" data-number="2"><h2 data-number="2" id="two-ways-to-get-the-data">
<span class="header-section-number">2</span> Two ways to get the data<a class="anchor" aria-label="anchor" href="#two-ways-to-get-the-data"></a>
</h2>
<p>There are two main ways to import the datasets:</p>
<ol type="1">
<li><p>as an in-memory object with <code><a href="../reference/spod_get.html">spod_get()</a></code>;</p></li>
<li><p>as a connection to DuckDB or Parquet files on disk with <code><a href="../reference/spod_convert.html">spod_convert()</a></code> + <code><a href="../reference/spod_connect.html">spod_connect()</a></code>. The latter is recommended for large datasets (more than 1 week), as it is much faster and more memory efficient, as we demonstarte below.</p></li>
</ol>
<p><code><a href="../reference/spod_get.html">spod_get()</a></code> returns objects that are only appropriate for small datasets representing a few days of the national origin-destination flows. We recommend converting the data into analysis-ready formats (<code>DuckDB</code> or <code>Parquet</code>) using <code><a href="../reference/spod_convert.html">spod_convert()</a></code> + <code><a href="../reference/spod_connect.html">spod_connect()</a></code>. This will allow you to work with much longer time periods (months and years) on a consumer laptop (with 8-16 GB of memory). See the section below for more details.</p>
</section><section class="section level2" data-number="3"><h2 data-number="3" id="analysis-large-datasets">
<span class="header-section-number">3</span> Analysing large datasets<a class="anchor" aria-label="anchor" href="#analysis-large-datasets"></a>
</h2>
<p>The mobility datasets available through <code>{spanishiddata}</code> are very large. Particularly the origin-destination data, which contains millions of rows. These data sets may not fit into the memory of your computer, especially if you plan to run the analysis over multiple days, weeks, months, or even years.</p>
<p>To work with these datasets, we highly recommend using <code>DuckDB</code> and <code>Parquet</code>. These are systems for efficiently processing larger-than-memory datasets, while being user-firendly by presenting the data in a familiar <code>data.frame</code>/<code>tibble</code> object (almost). For a great intoroduction to both, we recommend materials by Danielle Navarro, Jonathan Keane, and Stephanie Hazlitt: <a href="https://arrow-user2022.netlify.app/" target="_blank" class="external-link">website</a>, <a href="https://arrow-user2022.netlify.app/slides" target="_blank" class="external-link">slides</a>, and <a href="https://www.youtube.com/watch?v=YZMuFavEgA4" target="_blank" class="external-link">the video tutorial</a>. You can also find examples of aggregating origin-destination data for flows analysis and visualisation in our vignettes on <a href="flowmaps-static.html">static</a> and interactive (TODO: add link) flows visualisation.</p>
<p>Learning to use <code>DuckDB</code> and <code>Parquet</code> is easy for anyone who have ever worked with <a href="https://dplyr.tidyverse.org" class="external-link">dplyr</a> functions such as <code>select()</code>, <code><a href="https://rdrr.io/r/stats/filter.html" class="external-link">filter()</a></code>, <code>mutate()</code>, <code>group_by()</code>, <code>summarise()</code>, etc. However, since there is some learning curve to master these new tools, we provide some helper functions for novices to get started and easily open the datasets from <code>DuckDB</code> and <code>Parquet</code>. Please read the relevant sections below, where we first show how to convert the data, and then how to use it.</p>
<section class="level2" data-number="3.1"><h3 data-number="3.1" id="duckdb-vs-parquet-csv">
<span class="header-section-number">3.1</span> How to choose between DuckDB, Parquet, and CSV<a class="anchor" aria-label="anchor" href="#duckdb-vs-parquet-csv"></a>
</h3>
<p>The main considerations to make when choosing between <code>DuckDB</code> and <code>Parquet</code> (that you can get with <code><a href="../reference/spod_convert.html">spod_convert()</a></code> + <code><a href="../reference/spod_connect.html">spod_connect()</a></code>), as well as <code>CSV.gz</code> (that you can get with <code><a href="../reference/spod_get.html">spod_get()</a></code>) are analysis speed, convenience of data analysis, and the specific approach you prefer when getting the data. We discuss all three below.</p>
<section class="level3" data-number="3.1.1"><h4 data-number="3.1.1" id="speed-comparison">
<span class="header-section-number">3.1.1</span> Analysis Speed<a class="anchor" aria-label="anchor" href="#speed-comparison"></a>
</h4>
<p>The data format you choose may dramatically impact the speed of analysis (e.g. filtering by dates, calculating number of trips per hour, per week, per month, per origin-destination pair, and any other data aggregation or manipulation).</p>
<p>In our tests (see <a href="#fig-csv-duckdb-parquet-speed" class="quarto-xref">Figure 1</a>), we found that conducting an analysis using <code>DuckDB</code> database provided a significant speed advantage over using <code>Parquet</code> and, more importantly, raw <code>CSV.gz</code> files. Specifically, when comparing a query to determine the mean hourly trips over 18 months for each zone pair, we observed that using <code>DuckDB</code> database was <strong>up to 5 times</strong> faster than using <code>Parquet</code> files and <strong>up to 8 times</strong> faster than using <code>CSV.gz</code> files.</p>
<div id="fig-csv-duckdb-parquet-speed" class="quarto-float quarto-figure quarto-figure-center">
<figure class="quarto-float quarto-float-fig"><div aria-describedby="fig-csv-duckdb-parquet-speed-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="media/duckdb-parquet-csv-speed-mean-hourly-v1.svg">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-csv-duckdb-parquet-speed-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure 1: Data processing speed comparison: DuckDB engine running on CSV.gz files vs DuckDB database vs a folder of Parquet files
</figcaption></figure>
</div>
<details><summary>
You can see the query we used for measuring the speed here
</summary><p>For reference, here is a simple query we used for speed comparison in <a href="#fig-csv-duckdb-parquet-speed" class="quarto-xref">Figure 1</a>:</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># data represents either CSV files acquired from `spod_get()`, a `DuckDB` database or a folder of Parquet files connceted with `spod_connect()`</span></span>
<span><span class="va">data</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">group_by</span><span class="op">(</span><span class="va">id_origin</span>, <span class="va">id_destination</span>, <span class="va">time_slot</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu">summarise</span><span class="op">(</span>mean_hourly_trips <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html" class="external-link">mean</a></span><span class="op">(</span><span class="va">n_trips</span>, na.rm <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>,</span>
<span>    .groups <span class="op">=</span> <span class="st">"drop"</span><span class="op">)</span></span></code></pre></div>
</details><p><a href="#fig-csv-duckdb-parquet-speed" class="quarto-xref">Figure 1</a> also shows that <code>DuckDB</code> format will give you the best performance even on low-end systems with limited memory and number of processor cores, conditional on a fast SSD storage. Also note, that if you do choose to work with long time periods using CSV.gz files via <code><a href="../reference/spod_get.html">spod_get()</a></code>, you will need to balance the amount of memory and processor cores via the <code>max_n_cpu</code> and <code>max_mem_gb</code> arguments, otherwise the analysis may fail (see the grey area in the figure), when there are too many parallel processes running at the same time with limited memory.</p>
</section><section class="level3" data-number="3.1.2"><h4 data-number="3.1.2" id="convenience-of-data-analysis">
<span class="header-section-number">3.1.2</span> Convenience of data analysis<a class="anchor" aria-label="anchor" href="#convenience-of-data-analysis"></a>
</h4>
<p>Regardless of the data format (<code>DuckDB</code>, <code>Parquet</code>, or <code>CSV.gz</code>), the functions you will need for data manipulation and analysis are the same. This is because the analysis is actually performed by the <code>DuckDB</code> <span class="citation" data-cites="duckdb-r">(<a href="#ref-duckdb-r" role="doc-biblioref">Mühleisen and Raasveldt 2024</a>)</span> engine, which presents the data as if it were a regular <code>data.frame</code>/<code>tibble</code> object in R (almost). So from that point of view, there is no difference between the data formats. You can manipulate the data using <a href="https://dplyr.tidyverse.org" class="external-link">dplyr</a> functions such as <code>select()</code>, <code><a href="https://rdrr.io/r/stats/filter.html" class="external-link">filter()</a></code>, <code>mutate()</code>, <code>group_by()</code>, <code>summarise()</code>, etc. In the end of any sequence of commands you will need to add <code>collect()</code> to execute the whole chain of data manipulations and load the results into memory in an R <code>data.frame</code>/<code>tibble</code>. We provide examples in the following sections. Please refer to the recommended external tutorials and our own vignettes in the <a href="#analysing-large-datasets">Analysing large datasets</a> section.</p>
</section><section class="level3" data-number="3.1.3"><h4 data-number="3.1.3" id="scenarios-of-getting-the-data">
<span class="header-section-number">3.1.3</span> Scenarios of getting the data<a class="anchor" aria-label="anchor" href="#scenarios-of-getting-the-data"></a>
</h4>
<p>The choice between converting to <code>DuckDB</code> and <code>Parquet</code> could also be made based on how you plan to work with the data. Specifically whether you want to just download long periods or even all available data, or if you want to get the data gradually, as you progress through with the analysis.</p>
<ul>
<li><p>If you plan to work with long time periods, we recommend <code>DuckDB</code>, as it is one big file and it is easier to update it completely. For example you may be working with all 2020 data. Later you decide to add all of 2021 data. In this case it would be better to delete the database and create it from scratch.</p></li>
<li><p>If you only want certain dates, analyse them and add additional dates later, <code>Parquet</code> may be better, as each day is saved in a separate file, just like the original CSV files. Therefore updating a folder of <code>Parquet</code> files is as easy as just creating a new file only for the missing date.</p></li>
<li><p>If you only work with a few individual days, you may not notice the advantages of the <code>DuckDB</code> or <code>Parquet</code> formats. In this case, you can keep using the <code>CSV.gz</code> format for the analysis using the <code><a href="../reference/spod_get.html">spod_get()</a></code> function. This is also useful for quick tutorials, where you only need one or two days of data for demonstration purposes.</p></li>
</ul></section></section></section><section class="section level2" data-number="4"><h2 data-number="4" id="setup">
<span class="header-section-number">4</span> Setup<a class="anchor" aria-label="anchor" href="#setup"></a>
</h2>
<p>Make sure you have loaded the package:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://rOpenSpain.github.io/spanishoddata/">spanishoddata</a></span><span class="op">)</span></span></code></pre></div>
</div>
<section class="level2" data-number="4.1"><h3 data-number="4.1" id="set-data-folder">
<span class="header-section-number">4.1</span> Set the data directory<a class="anchor" aria-label="anchor" href="#set-data-folder"></a>
</h3>
<p>Choose where <a href="https://rOpenSpain.github.io/spanishoddata/">spanishoddata</a> should download (and convert) the data by setting the <code>SPANISH_OD_DATA_DIR</code> environment variable with the following command:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Sys.setenv.html" class="external-link">Sys.setenv</a></span><span class="op">(</span>SPANISH_OD_DATA_DIR <span class="op">=</span> <span class="st">"~/spanish_od_data"</span><span class="op">)</span></span></code></pre></div>
</div>
<p>The package will create this directory if it does not exist on the first run of any function that downloads the data.</p>
<details><summary>
Setting data directory for advanced users
</summary><p>To permanently set the directory for all projects, you can specify the data directory globally by setting the <code>SPANISH_OD_DATA_DIR</code> environment variable, e.g. with the following command:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">usethis</span><span class="fu">::</span><span class="fu"><a href="https://usethis.r-lib.org/reference/edit.html" class="external-link">edit_r_environ</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="co"># Then set the data directory globally, by typing this line in the file:</span></span></code></pre></div>
</div>
<pre><code><span><span class="va">SPANISH_OD_DATA_DIR</span> <span class="op">=</span> <span class="st">"~/spanish_od_data"</span></span></code></pre>
<p>You can also set the data directory locally, just for the current project. Set the ‘envar’ in the working directory by editing <code>.Renviron</code> file in the root of the project:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/file.edit.html" class="external-link">file.edit</a></span><span class="op">(</span><span class="st">".Renviron"</span><span class="op">)</span></span></code></pre></div>
</div>
</details></section></section><section class="section level2" data-number="5"><h2 data-number="5" id="spod-get">
<span class="header-section-number">5</span> Getting a single day with <code>spod_get()</code>
<a class="anchor" aria-label="anchor" href="#spod-get"></a>
</h2>
<p>As you might have seen in the codebooks for <a href="v1-2020-2021-mitma-data-codebook.html">v1</a> and <a href="v2-2022-onwards-mitma-data-codebook.html">v2</a> data, you can get a single day’s worth of data as an in-memory object with <code><a href="../reference/spod_get.html">spod_get()</a></code>:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">dates</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"2024-03-01"</span><span class="op">)</span></span>
<span><span class="va">d_1</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/spod_get.html">spod_get</a></span><span class="op">(</span>type <span class="op">=</span> <span class="st">"od"</span>, zones <span class="op">=</span> <span class="st">"distr"</span>, dates <span class="op">=</span> <span class="va">dates</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/class.html" class="external-link">class</a></span><span class="op">(</span><span class="va">d_1</span><span class="op">)</span></span></code></pre></div>
</div>
<p>The output should look like this:</p>
<pre><code># Source:   table&lt;od_csv_clean_filtered&gt; [?? x 19]
# Database: DuckDB v1.0.0 [... 6.5.0-45-generic:R 4.4.1/:memory:]
   date       time_slot id_origin id_destination distance activity_origin
   &lt;date&gt;         &lt;int&gt; &lt;fct&gt;     &lt;fct&gt;          &lt;fct&gt;    &lt;fct&gt;
 1 2024-03-01        19 01009_AM  01001          0.5-2    frequent_activity
 2 2024-03-01        15 01002     01001          10-50    frequent_activity</code></pre>
<p>Note that this is a lazily-evaluated in-memory object (note the <code>:memory:</code> in the database path). This means that the data is not loaded into memory until you call <code>collect()</code> on it. While this is useful for quick exploration of the data, we do not recommended this for large datasets, as we have demonstrated <a href="#speed-comparison">above</a>.</p>
</section><section class="section level2" data-number="6"><h2 data-number="6" id="duckdb">
<span class="header-section-number">6</span> Analysing the data using <code>DuckDB</code> database<a class="anchor" aria-label="anchor" href="#duckdb"></a>
</h2>
<p>Please make sure you did all the steps in the <a href="#setup">Setup</a> section above.</p>
<section class="level2" data-number="6.1"><h3 data-number="6.1" id="convert-to-duckdb">
<span class="header-section-number">6.1</span> Convert to <code>DuckDB</code>
<a class="anchor" aria-label="anchor" href="#convert-to-duckdb"></a>
</h3>
<p>You can download and convert the data into <code>DuckDB</code> database in two steps. For example, you select a few dates, and download the data manually (note: we use <code>dates_2</code> to refer to the fact that we are using v2 data):</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">dates_2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span>start <span class="op">=</span> <span class="st">"2023-02-14"</span>, end <span class="op">=</span> <span class="st">"2023-02-17"</span><span class="op">)</span></span>
<span><span class="fu"><a href="../reference/spod_download_data.html">spod_download_data</a></span><span class="op">(</span>type <span class="op">=</span> <span class="st">"od"</span>, zones <span class="op">=</span> <span class="st">"distr"</span>, dates <span class="op">=</span> <span class="va">dates_2</span><span class="op">)</span></span></code></pre></div>
</div>
<p>After that, you can convert any downloaded data (including the files that might have been downloaded previosly by running <code><a href="../reference/spod_get.html">spod_get()</a></code> or <code><a href="../reference/spod_download_data.html">spod_download_data()</a></code> with other dates or date intervals) into <code>DuckDB</code> like so (<code>dates = "cached_v2"</code> means use <em>all</em> downloaded files):</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">db_2</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/spod_convert.html">spod_convert</a></span><span class="op">(</span>type <span class="op">=</span> <span class="st">"od"</span>, zones <span class="op">=</span> <span class="st">"distr"</span>, dates <span class="op">=</span> <span class="st">"cached_v2"</span>, save_format <span class="op">=</span> <span class="st">"duckdb"</span>, overwrite <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="va">db_2</span> <span class="co"># check the path to the saved `DuckDB` database</span></span></code></pre></div>
</div>
<p>The <code>dates = "cached_v2"</code> (which can also be <code>dates = "cached_v1"</code> for v1 data) argument instructs the function to only work with already-downloaded files. By default this resulting <code>DuckDB</code> database for v2 origin-destination data for districts will be saved in the <code>SPANISH_OD_DATA_DIR</code> directory under <code>v2/tabular/duckdb/</code> with filename <code>od_distritos.duckdb</code> (you can change this file path with the <code>save_path</code> argument). The function returns the full path to the database file, which we save into <code>db_2</code> variable. You can also any desired save location with the <code>save_path</code> argument of <code><a href="../reference/spod_convert.html">spod_convert()</a></code>.</p>
<p>You can also convert any dates range or dates list to <code>DuckDB</code>:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">dates_1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span>start <span class="op">=</span> <span class="st">"2020-02-17"</span>, end <span class="op">=</span> <span class="st">"2020-02-19"</span><span class="op">)</span></span>
<span><span class="va">db_2</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/spod_convert.html">spod_convert</a></span><span class="op">(</span>type <span class="op">=</span> <span class="st">"od"</span>, zones <span class="op">=</span> <span class="st">"distr"</span>, dates <span class="op">=</span> <span class="va">dates_1</span>, overwrite <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code></pre></div>
</div>
<p>In this case, any missing data that has now yet been downloaded will be automatically downloaded, while 2020-02-17 will not be redownloaded, as we already requsted it when creating <code>db_1</code>. Then the requested dates will be converted into <code>DuckDB</code>, overwriting the file with <code>db_1</code>. Once again, we save the path to the output <code>DuckDB</code> database file into <code>db_2</code> variable.</p>
</section><section class="level2" data-number="6.2"><h3 data-number="6.2" id="load-converted-duckdb">
<span class="header-section-number">6.2</span> Load the converted <code>DuckDB</code>
<a class="anchor" aria-label="anchor" href="#load-converted-duckdb"></a>
</h3>
<p>You can read the introductory information on how to connect to <code>DuckDB</code> files <a href="https://duckdb.org/docs/api/r" target="_blank" class="external-link">here</a>, however to simplify things for you we created a helper function. So to connect to the data stored in at path <code>db_1</code> and <code>db_2</code> you can do the following:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">my_od_data_2</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/spod_connect.html">spod_connect</a></span><span class="op">(</span><span class="va">db_2</span><span class="op">)</span></span></code></pre></div>
</div>
<p>Just like before, with <code><a href="../reference/spod_get.html">spod_get()</a></code> funciton that we used to download raw CSV.gz files and analyse them without any conversion, the resulting object <code>my_od_data_2</code> is also a <code>tbl_duckdb_connection</code>. So, you can treat it as regular <code>data.frame</code> or <code>tibble</code> and use <a href="https://dplyr.tidyverse.org" class="external-link">dplyr</a> functions such as <code>select()</code>, <code><a href="https://rdrr.io/r/stats/filter.html" class="external-link">filter()</a></code>, <code>mutate()</code>, <code>group_by()</code>, <code>summarise()</code>, etc. For analysis, please refer to the recommended external tutorials and our own vignettes in the <a href="#analysing-large-datasets">Analysing large datasets</a> section.</p>
<p>After finishing working with <code>my_od_data_2</code> we advise that you “disconnect” this data using:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/spod_disconnect.html">spod_disconnect</a></span><span class="op">(</span><span class="va">my_od_data_2</span><span class="op">)</span></span></code></pre></div>
</div>
<p>This is useful to free-up memory and is neccessary if you would like to run <code><a href="../reference/spod_convert.html">spod_convert()</a></code> again and save the data to the same location. Otherwise, it is also helpful to avoid unnecessary possible warnings in terminal for garbage collected connections.</p>
</section></section><section class="section level2" data-number="7"><h2 data-number="7" id="parquet">
<span class="header-section-number">7</span> Analysing the data using <code>Parquet</code>
<a class="anchor" aria-label="anchor" href="#parquet"></a>
</h2>
<p>Please make sure you did all the steps in the <a href="#setup">Setup</a> section above.</p>
<section class="level2" data-number="7.1"><h3 data-number="7.1" id="convert-to-parquet">
<span class="header-section-number">7.1</span> Convert to <code>Parquet</code>
<a class="anchor" aria-label="anchor" href="#convert-to-parquet"></a>
</h3>
<p>The process is exactly the same as for <code>DuckDB</code> above. The only difference is that the data is converted to <code>parquet</code> format and stored in <code>SPANISH_OD_DATA_DIR</code> under <code>v1/clean_data/tabular/parquet/</code> directory for v1 data (change this with the <code>save_path</code> argument), and the subfolders are in hive-style format like <code>year=2020/month=2/day=14</code> and inside each of these folders a single <code>parquet</code> file will be placed containing the data for that day.</p>
<p>The advantage of this format is that you can “update” it quickly. For example, if you first downloaded the data for March and April 2020, converted this period into <code>parquet</code> format, and then downloaded the data for May and June 2020, when you run the convertion function again, it will only convert the data for May and June 2020 and add it to the existing <code>parquet</code> files. So you will save time and will not have to wait for March and April 2020 to be converted again.</p>
<p>Let us convert a few dates to <code>parquet</code> format:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">type</span> <span class="op">&lt;-</span> <span class="st">"od"</span></span>
<span><span class="va">zones</span> <span class="op">&lt;-</span> <span class="st">"distr"</span></span>
<span><span class="va">dates</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span>start <span class="op">=</span> <span class="st">"2020-02-14"</span>, end <span class="op">=</span> <span class="st">"2020-02-17"</span><span class="op">)</span></span>
<span><span class="va">od_parquet</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/spod_convert.html">spod_convert</a></span><span class="op">(</span>type <span class="op">=</span> <span class="va">type</span>, zones <span class="op">=</span> <span class="va">zones</span>, dates <span class="op">=</span> <span class="va">dates</span>, save_format <span class="op">=</span> <span class="st">"parquet"</span><span class="op">)</span></span></code></pre></div>
</div>
<p>If we now request additional dates that overlap with the already converted data like so and specifiy argument <code>overwrite = 'update'</code> we will update the existing <code>parquet</code> files with the new data:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb15"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">dates</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span>start <span class="op">=</span> <span class="st">"2020-02-16"</span>, end <span class="op">=</span> <span class="st">"2020-02-19"</span><span class="op">)</span></span>
<span><span class="va">od_parquet</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/spod_convert.html">spod_convert</a></span><span class="op">(</span>type <span class="op">=</span> <span class="va">type</span>, zones <span class="op">=</span> <span class="va">zones</span>, dates <span class="op">=</span> <span class="va">dates</span>, save_format <span class="op">=</span> <span class="st">"parquet"</span>, overwrite <span class="op">=</span> <span class="st">'update'</span><span class="op">)</span></span></code></pre></div>
</div>
<p>That is, 16 and 17 Feboruary will not be converted again. Only the new data, that was not converted (18 and 19 February) will be converted, and these will be added to the existing folder structure of<code>parquet</code> files stored at the default <code>save_path</code> location, which is <code>&lt;data_dir&gt;/clean_data/v1/tabular/parquet/od_distritos</code>. Alternatively, you can set any other save location by setting the <code>save_path</code> argument.</p>
</section><section class="level2" data-number="7.2"><h3 data-number="7.2" id="load-converted-parquet">
<span class="header-section-number">7.2</span> Load the converted <code>Parquet</code>
<a class="anchor" aria-label="anchor" href="#load-converted-parquet"></a>
</h3>
<p>Working with these <code>parquet</code> files is exactly the same as with <code>DuckDB</code> and <code>Arrow</code> files. Just like before, you can use the same helper function <code><a href="../reference/spod_connect.html">spod_connect()</a></code> to connect to the <code>parquet</code> files:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb16"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">my_od_data_3</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/spod_connect.html">spod_connect</a></span><span class="op">(</span><span class="va">od_parquet</span><span class="op">)</span></span></code></pre></div>
</div>
<p>Mind you though, because we have first converted the data for a period between 14 and 17 February 2020, and then converted the data for a period between 16 and 19 February 2020 into the save default location, the <code>od_parquet</code> contains the path to all this data, and therefore <code>my_od_data_3</code> will connect you to all data.</p>
<p>You can check this like so:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb17"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">my_od_data_3</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu">dplyr</span><span class="fu">::</span><span class="fu"><a href="https://dplyr.tidyverse.org/reference/distinct.html" class="external-link">distinct</a></span><span class="op">(</span><span class="va">date</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">dplyr</span><span class="fu">::</span><span class="fu"><a href="https://dplyr.tidyverse.org/reference/arrange.html" class="external-link">arrange</a></span><span class="op">(</span><span class="va">date</span><span class="op">)</span></span></code></pre></div>
</div>
<p>For analysis, please refer to the recommended external tutorials and our own vignettes in the <a href="#analysing-large-datasets">Analysing large datasets</a> section.</p>
</section></section><section class="section level2" data-number="8"><h2 data-number="8" id="all-dates">
<span class="header-section-number">8</span> Download all available data<a class="anchor" aria-label="anchor" href="#all-dates"></a>
</h2>
<p>To prepare origin-destination data v1 (2020-2021) for analysis over the whole period of data availability, please follow the steps below:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb18"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">dates_v1</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/spod_get_valid_dates.html">spod_get_valid_dates</a></span><span class="op">(</span>ver <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span>
<span><span class="va">dates_v2</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/spod_get_valid_dates.html">spod_get_valid_dates</a></span><span class="op">(</span>ver <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span></code></pre></div>
</div>
<p>Due to mobile network outages, some dates are missing, so do not assume that a simple interval between two dates will just work. Currently <a href="https://www.transportes.gob.es/ministerio/proyectos-singulares/estudios-de-movilidad-con-big-data/opendata-movilidad" target="_blank" class="external-link">known outages</a> are: 26, 27, 30, 31 October, 1, 2 and 3 November 2023 and 4, 18, 19 April 2024. This is why it is adviseable to use <code><a href="../reference/spod_get_valid_dates.html">spod_get_valid_dates()</a></code> function to get all possible dates from available data.</p>
<section class="level2" data-number="8.1"><h3 data-number="8.1" id="download-all-data">
<span class="header-section-number">8.1</span> Download all data<a class="anchor" aria-label="anchor" href="#download-all-data"></a>
</h3>
<p>Here the example is for origin-destination on district level for v1 data. You can change the <code>type</code> to “number_of_trips” and the <code>zones</code> to “municipalities” for v1 data. For v2 data, just use <code>dates</code> starting with 2022-01-01 or the <code>dates_v2</code> from above. Use all other function arguments for v2 in the same way as shown for v1, but also consult the <a href="v2-2022-onwards-mitma-data-codebook.html">v2 data codebook</a>, as it has many more datasets in addition to “origin-destination” and “number_of_trips”.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb19"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">type</span> <span class="op">&lt;-</span> <span class="st">"origin-destination"</span></span>
<span><span class="va">zones</span> <span class="op">&lt;-</span> <span class="st">"districts"</span></span>
<span><span class="fu"><a href="../reference/spod_download_data.html">spod_download_data</a></span><span class="op">(</span></span>
<span>  type <span class="op">=</span> <span class="va">type</span>,</span>
<span>  zones <span class="op">=</span> <span class="va">zones</span>,</span>
<span>  dates <span class="op">=</span> <span class="va">dates_v1</span>,</span>
<span>  return_output <span class="op">=</span> <span class="cn">FALSE</span>, <span class="co"># to avoid getting all downloaded files printed to console</span></span>
<span>  max_download_size_gb <span class="op">=</span> <span class="fl">50</span> <span class="co"># in Gb, this should be well over the actual download size for v1 data</span></span>
<span><span class="op">)</span></span></code></pre></div>
</div>
</section><section class="level2" data-number="8.2"><h3 data-number="8.2" id="convert-all-data-into-analysis-ready-format">
<span class="header-section-number">8.2</span> Convert all data into analysis ready format<a class="anchor" aria-label="anchor" href="#convert-all-data-into-analysis-ready-format"></a>
</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb20"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">save_format</span> <span class="op">&lt;-</span> <span class="st">"duckdb"</span></span>
<span></span>
<span><span class="va">analysis_data_storage</span> <span class="op">&lt;-</span> <span class="fu">spod_convert_data</span><span class="op">(</span></span>
<span>  type <span class="op">=</span> <span class="va">type</span>,</span>
<span>  zones <span class="op">=</span> <span class="va">zones</span>,</span>
<span>  dates <span class="op">=</span> <span class="st">"cached_v1"</span>, <span class="co"># to just convert all data that was previously downloaded, no need to specify dates here</span></span>
<span>  save_format <span class="op">=</span> <span class="va">save_format</span>,</span>
<span>  overwrite <span class="op">=</span> <span class="cn">TRUE</span></span>
<span><span class="op">)</span></span></code></pre></div>
</div>
<p>This will convert all downloaded data to <code>DuckDB</code> format for lightning fast analysis. You can change the <code>save_format</code> to <code>parquet</code> if you want to save the data in <code>Parquet</code> format. For comparison overview of the two formats please see the <a href="converting-the-data-for-faster-analysis.html">Converting the data to DuckDB/Parquet for faster analysis</a>.</p>
<p>By default, <code>spod_convert_data()</code> will save the converted data in the <code>SPANISH_OD_DATA_DIR</code> directory. You can change the <code>save_path</code> argument of <code>spod_convert_data()</code> if you want to save the data in a different location.</p>
<p>For this conversion, 4 GB or operating memory should be enough, the speed of the process depends on the number of processor cores and the speed of your disk storage. SSD is preferred. By default, the <code>spod_convert_data()</code> will use all except one processor cores on your computer. You can adjust this with the <code>max_n_cpu</code> argument of <code>spod_convert_data()</code>. You can also increase the maximum amount of memory used with the <code>max_mem_gb</code> argument, but this makes more difference during the analysis stage.</p>
<p>Finally, <code>analysis_data_storage</code> will simply store the path to the converted data. Either a path to the <code>DuckDB</code> database file or a path to the folder with <code>Parquet</code> files.</p>
</section><section class="level2" data-number="8.3"><h3 data-number="8.3" id="conversion-speed">
<span class="header-section-number">8.3</span> Conversion speed<a class="anchor" aria-label="anchor" href="#conversion-speed"></a>
</h3>
<p>For reference, converting the whole v1 origin-destination data to <code>DuckDB</code> takes about 20 minutes with 4 GB of memory and 3 processor cores. The final size of the <code>DuckDB</code> database is about 18 GB, in <code>Parquet</code> format - 26 GB. The raw CSV files in gzip archives are about 20GB. v2 data is much larger, with origin-destination tables for 2022 - mid-2024 taking up 150+ GB in raw CSV.gz format.</p>
</section><section class="level2" data-number="8.4"><h3 data-number="8.4" id="connecting-to-and-analysing-the-converted-datasets">
<span class="header-section-number">8.4</span> Connecting to and analysing the converted datasets<a class="anchor" aria-label="anchor" href="#connecting-to-and-analysing-the-converted-datasets"></a>
</h3>
<p>You can pass the <code>analysis_data_storage</code> path to <code><a href="../reference/spod_connect.html">spod_connect()</a></code> function, whether it is <code>DuckDB</code> or <code>Parquet</code>. The function will determine the data type automatically and give you back a <code>tbl_duckdb_connection</code><a class="footnote-ref" role="doc-noteref" tabindex="0" data-bs-toggle="popover" data-bs-content="&lt;p&gt;For reference: this object also has classes: &lt;code&gt;tbl_dbi&lt;/code&gt; ,&lt;code&gt;tbl_sql&lt;/code&gt;, &lt;code&gt;tbl_lazy&lt;/code&gt; ,and &lt;code&gt;tbl&lt;/code&gt; .&lt;/p&gt;"><sup>1</sup></a>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb21"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">my_data</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/spod_connect.html">spod_connect</a></span><span class="op">(</span></span>
<span>  data_path <span class="op">=</span> <span class="va">analysis_data_storage</span>, </span>
<span>  max_mem_gb <span class="op">=</span> <span class="fl">16</span></span>
<span><span class="op">)</span></span></code></pre></div>
</div>
<p>Here we set <code>max_mem_gb</code> to 16 GB. Generally, if you have more, feel free to increase it, but also consult the <a href="#fig-csv-duckdb-parquet-speed" class="quarto-xref">Figure 1</a> with our speed testing results in the <a href="#speed-comparison">Speed</a> section. You can try other combinations of <code>max_mem_gb</code> and <code>max_n_cpu</code> arguments for your needs</p>
<p>Compared to conversion process, you might want to increase the available memory for the analysis step. The more, the better. You can control that with the <code>max_mem_gb</code> argument.</p>
<p>You can manipulate <code>my_data</code> using <a href="https://dplyr.tidyverse.org" class="external-link">dplyr</a> functions such as <code>select()</code>, <code><a href="https://rdrr.io/r/stats/filter.html" class="external-link">filter()</a></code>, <code>mutate()</code>, <code>group_by()</code>, <code>summarise()</code>, etc. In the end of any sequence of commands you will need to add <code>collect()</code> to execute the whole chain of data manipulations and load the results into memory in an R <code>data.frame</code>/<code>tibble</code>. For analysis, please refer to the recommended external tutorials and our own vignettes in the <a href="#analysing-large-datasets">Analysing large datasets</a> section.</p>
<p>After finishing working with <code>my_data</code> we advise that you “disconnect” to free up memory:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb22"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/spod_disconnect.html">spod_disconnect</a></span><span class="op">(</span><span class="va">my_data</span><span class="op">)</span></span></code></pre></div>
</div>
<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-duckdb-r" class="csl-entry" role="listitem">
Mühleisen, Hannes, and Mark Raasveldt. 2024. <em>Duckdb: DBI Package for the DuckDB Database Management System</em>. <a href="https://doi.org/10.32614/CRAN.package.duckdb" class="external-link">https://doi.org/10.32614/CRAN.package.duckdb</a>.
</div>
</div>
</section></section><script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'light-border',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config);
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script></main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>


   </div>

  <!-- ropenspain rostemplate -->
<footer id="footer"><div class="container">
    <div class="row">
      <div class="col-md">
        <h4 data-toc-skip>About <img src="../logo.png" alt="spanishoddata Logo" height="24"> spanishoddata</h4>
        <p>Developed by <a href="https://www.ekotov.pro" class="external-link">Egor Kotov</a>, <a href="https://www.robinlovelace.net/" class="external-link">Robin Lovelace</a>.</p>
        <p>Part of the <span class="ROS-light">rOpenSpain</span> project.</p>
        <hr class="d-md-none">
</div>
      <div class="col-md offset-md-4">
        <h4 data-toc-skip>About <img src="../ROS-logo.png" alt="ROpenSpain Logo" height="24"><span class="ROS-light"> rOpenSpain</span>
</h4>
        <a href="https://ropenspain.es/" class="external-link"><span class="ROS-light">rOpenSpain</span></a> is a community of R enthusiasts whose ultimate goal is to create high-quality R packages for data mining public Spanish open sources.
        <hr class="d-md-none">
</div>
   </div>
  </div>
</footer><div id="copyright">
  <div class="container">
    <div class="row">
      <div class="col-md text-center text-lg-start">
        <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.0.</p>
      </div>
      <div class="col-md offset-md-4 text-center text-lg-start">
      <p>Template <a href="https://github.com/ropenspain/rostemplate/" class="external-link">rostemplate</a> by <a href="https://github.com/dieghernan/" class="external-link">dieghernan</a>, based on <a href="https://bootstrapious.com/" class="external-link">Bootstrapious</a>.
      </p>
      </div>
    </div>
  </div>
</div>




  <script>
var h1s = document.getElementsByTagName("h1");
var myH1;
if (h1s.length > 0) {
  myH1 = h1s[0];
  myH1.classList.add("ROSh1");
}
</script>
</body>
</html>
